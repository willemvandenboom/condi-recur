---
title: "Simulation study with a misspecified model"
author: "Willem van den Boom"
output: html_document
---


## Generate data according to the model

The following uses parallel computing which I have only tested on macOS and
Linux and might therefore not work on Windows operating systems.

```{r eval=FALSE}
# For parallel computing
if(!'doParallel' %in% rownames(installed.packages())) {
  install.packages('doParallel', dependencies = T)
}

censoring_rate <- c(0, 0.5, 0.8, 0.9)
n_cr <- length(censoring_rate)


# Set seed for reproducibility.
set.seed(1L)

L <- 150L # Number of individuals
s <- rep(1:3, L %/% 3) # Cluster allocation
K <- max(s) # Number of clusters

# Generate the covariate values and their effects.
q = 2
x = matrix(data = runif(L * q), nrow = L, ncol = q)
beta = c(-1, 1)
gamma = c(-1, 1)

# Specify the random effects.
m <- matrix(data = NA_real_, nrow = L, ncol = 2)
m[, 1] <- s
for (h in 1:K) m[s == h, 2] <- (h - 2) * 0.8
delta <- s + 4

sigma2 <- 1
eta2 <- 1
r <- 1
lambda <- 7

N <- rnbinom(n = L, size = r, mu = lambda)
N_max <- max(N)

# Function that samples from the Gompertz distribution with shape parameter
# `eta` and scale parameter `b`.
rgompertz <- function(n, eta, b) log1p(-log1p(-runif(n)) / eta) / b

# We therefore use `pmin` to avoid overflow.
S <- pmin(rgompertz(
  n = L, eta = 0.01, b = exp(-as.vector(x %*% gamma + delta))
), 1e100)

# Generate Y and S using rejection sampling.
Y <- matrix(data = NA_real_, nrow = L, ncol = N_max)
T_all <- Y

for (i in 1:L) if (N[i] > 0) {
  T_all[i, N[i]] <- Inf
  
  while(T_all[i, N[i]] > S[i]) for (j in 1:N[i]) {
    
    Y[i, j] <- rnorm(
      n = 1,
      mean = x[i, ] %*% beta + m[i, 1] + if (j > 1) m[i, 2] * (
        Y[i, j - 1L] - x[i, ] %*% beta - m[i, 1]
      ) else 0,
      sd = sqrt(sigma2)
    )
    
    T_all[i, j] <- exp(Y[i, j]) + if (j > 1) T_all[i, j - 1L] else 0
    
    S[i] <- pmin(rgompertz(
      n = 1, eta = 0.01, b = exp(-as.vector(sum(x[i, ] * gamma) + delta[i]))
    ), 1e100)
    
  }
}


# Simulate the censored data.
cens_c <- list()
c_i_c <- list()
n_c <- list()
T_obs_c <- list()
n_rep <- 1L

for (r in 1:(n_cr * n_rep)) {
  
  T_obs <- T_all
  n <- N
  c_i <- S
  
  cens <- rep(FALSE, L)
  cens[sample(
    L, size = round(censoring_rate[(r - 1L) %% n_cr + 1L] * L)
  )] <- TRUE
  
  for (i in which(cens)) {
    c_i[i] <- runif(n = 1, min = ifelse(N[i] > 0, T_all[i, 1], 0), max = S[i])
    tmp <- T_all[i, seq_len(N[i])] <= c_i[i]
    T_obs[i, !tmp] <- NA_real_
    n[i] <- sum(tmp)
  }
  
  cens_c[[r]] <- cens
  c_i_c[[r]] <- c_i
  n_c[[r]] <- n
  T_obs_c[[r]] <- T_obs[, 1:max(n)]
  
}


n_par <- n_rep * n_cr
seed_seq <- sample.int(.Machine$integer.max, size = n_par)


# Function used for parallelization
# It runs the Gibbs sampler on the data while cycling through the censoring rates for ind ≤ n_rep * n_cr.
run_Gibbs <- function (ind) {
  
  # Set seed for reproducibility.
  set.seed(seed_seq[ind])
  
  source("Gibbs_sampler.R")
  r <- ind
  mu_lambda <- 1
  
  return(Gibbs_sampler(
    T_obs = T_obs_c[[r]],
    n = n_c[[r]],
    c_i = c_i_c[[r]],
    cens = cens_c[[r]],
    x = x,
    n_iter = 2e5L,
    burnin = 2e4L,
    thin = 1e1L,
    a_lambda = mu_lambda^2,
    b_lambda = mu_lambda
  ))
  
}

cl <- parallel::makeCluster(parallel::detectCores())
doParallel::registerDoParallel(cl)
result_c <- foreach::`%dopar%`(foreach::foreach(ind = 1:n_par), run_Gibbs(ind))
parallel::stopCluster(cl)
```


```{r include=FALSE, eval=FALSE}
dir.create("Data", showWarnings = FALSE)
save.image(file = "Data/simulation_Gompertz.RData", compress = TRUE)
```

```{r include=FALSE, eval=TRUE}
load(file = "Data/simulation_Gompertz.RData")
```



## Number of events

Compute and plot the CIs.

```{r}
titles <- paste0(100 * censoring_rate, "% censored")

y <- rank(
  x = 10000L * N + 100L * n_c[[4]] + colMeans(result_c[[4]]$N),
  ties.method = "random"
)

pdf(
  file = paste0("Figures/N_CI_simulation_Gompertz.pdf"),
  width = 10,
  height = 15
)

par(mfrow = c(1, n_cr - 1), mar = c(4, 0, 3, 0))


for (r in 2:n_cr) {
  
  result <- result_c[[r]]
  n <- n_c[[r]]
  cens <- cens_c[[r]]

  N_CI <- matrix(data = NA_real_, nrow = L, ncol = 3)
  
  N_CI[, 1] <- colMeans(result$N)
  
  for (i in 1:L) N_CI[i, 2:3] <- quantile(result$N[, i], prob = c(0.025, 0.975))
  
  # Plot an 'o' at the actual number of events.
  plot(
    x = N,
    y = y,
    pch = 1,
    xlim = c(0, 61),
    xlab = expression(italic("N"["i"])),
    ylab = "",
    yaxt = "n",
    main = titles[r]
  )
   
  for (i in which(cens)) {
    
    lines(x = N_CI[i,-1], y = rep(y[i], 2), lwd = 2)
    
    # Add an 'x' at the number of observed recurrent events.
    points(x = n[i], y = y[i], pch = 4)
    
    # Add a solid dot at the posterior mean.
    points(x = N_CI[i, 1], y = y[i], pch = 19)
    
  }

}

dev.off()
```


## Posterior predictive distributions of δ, mi0 and mi1

```{r}
pdf(
  file = "Figures/m_delta_new_simulation_Gompertz.pdf", width = 6.5, height = 9
)

par(mfrow = c(n_cr, 2))
m_new_c <- list()
delta_new_c <- list()

for (rr in 1:n_cr) {
  
  result <- result_c[[rr]]
  
  n_rep_pred <- 3L
  n_recorded <- length(result$M)
  
  m_new <- matrix(NA_real_, nrow = n_rep_pred * n_recorded, ncol = 2)
  delta_new <- rep(NA_real_, n_rep_pred * n_recorded)
  
  sigma2_m <- 100
  sigma2_delta <- 100
  
  set.seed(1L)
  
  for (iter in 1:n_recorded) for (r in 1:n_rep_pred) {
    
    ind <- n_rep_pred * (iter - 1L) + r
    
    if (runif(1) < L / (result$M[iter] + L)) {
      i <- sample.int(L, size = 1)
      m_new[ind, ] <- result$m[iter, i, ]
      delta_new[ind] <- result$delta[iter, i]
    } else {
      m_new[ind, ] <- rnorm(2, sd = sqrt(sigma2_m))
      delta_new[ind] <- rnorm(1, sd = sqrt(sigma2_delta))
    }
    
  }
  
  m_new_c[[rr]] <- m_new
  delta_new_c[[rr]] <- delta_new
  delta_lim <- c(3.5, 12)
  
  plot_2D_density <- function(y, ylim, zlim, ylab) {
    
    tmp <- MASS::kde2d(
      x = delta_new,
      y = y,
      h = 2 * c(MASS::bandwidth.nrd(delta_new), MASS::bandwidth.nrd(y)),
      n = 200L,
      lims = c(
        delta_lim + c(-.05, .05) * diff(delta_lim),
        ylim + c(-.05, .05) * diff(ylim)
      )
    )
    
    contour(
      x = tmp$x,
      y = tmp$y,
      z = log(tmp$z),
      xlim = delta_lim,
      ylim = ylim,
      zlim = zlim,
      drawlabels = FALSE,
      xlab = expression(delta[i]),
      ylab = ylab,
      main = titles[rr]
    )
    
  }
  
  
  plot_2D_density(
    y = m_new[, 1],
    ylim = c(-1, 5),
    zlim = c(-5, 0),
    ylab = expression('m'[i1])
  )
  
  plot_2D_density(
    y = m_new[, 2],
    ylim = c(-2, 2),
    zlim = c(-4.5, 0),
    ylab = expression('m'[i2])
  )
  
}

dev.off()
```


## Marginal posterior density for $\sigma^2$ and the posterior predictives for $S_i$ and $N_i$

```{r}
x_mode <- rep(NA_real_, q)
for (j in 1:q) x_mode[j] <- median(x[, j])
S_new <- rep(NA_real_, n_rep_pred * n_recorded)

pdf(file = "Figures/variances_S_N_simulation_Gompertz.pdf", width = 6.5, height = 9)

par(mfrow = c(n_cr, 3))

for (rr in 1:n_cr) {
  
  max_N <- 30L
  N_pmf <- rep(0, max_N + 1L)
  result <- result_c[[rr]]
  
  for (iter in 1:n_recorded) {
    
    N_pmf <- N_pmf + dnbinom(
      x = 0:max_N, size = result$r[iter], mu = result$lambda[iter]
    )
    
    for (r in 1:n_rep_pred) {
      
      ind <- n_rep_pred * (iter - 1L) + r
      
      # Generate S_i using rejection sampling.
      T_N_i <- Inf
      S_i <- 0
    
      while (T_N_i > S_i) {
        
        S_i <- min(exp(rnorm(
          n = 1,
          mean = sum(x_mode * result$gamma[iter, ]) + delta_new_c[[rr]][ind],
          sd = sqrt(result$eta2[iter])
        )), 1e100)
        
        T_N_i <- 0
        N_i <- rnbinom(n = 1, size = result$r[iter], mu = result$lambda[iter])
        
        for (j in seq_len(N_i)) {
        
          Y_i <- rnorm(
            n = 1,
            mean = sum(
              x_mode * result$beta[iter, ]
            ) + m_new_c[[rr]][ind, 1] + if (j > 1) m_new_c[[rr]][ind, 2] * (
              Y_previous - sum(x_mode * result$beta[iter, ]) - m_new_c[[rr]][ind, 1]
            ) else 0,
            sd = sqrt(result$sigma2[iter])
          )
          
          Y_previous <- Y_i
          T_N_i <- T_N_i + exp(Y_i)
          
        }
      
      }
      
      S_new[ind] <- S_i
      
    }
    
  }
  
  plot(
    x = density(result$sigma2, from = 0.9, to = 1.4),
    main = "",
    xlab = expression(sigma^2),
    lwd = 2
  )
  
  plot(
    x = density(log(S_new), from = 2, to = 17),
    main = titles[rr],
    xlab = expression(log(S[i])),
    ylab = "Posterior predictive density",
    lwd = 2
  )
  
  barplot(
    height = N_pmf / n_recorded,
    names.arg = 0:max_N,
    main = "",
    xlab = expression(N[i]),
    ylab = "Posterior predictive probability"
  )
  
}

dev.off()
```


```{r}
x_mode <- rep(NA_real_, q)
for (j in 1:q) x_mode[j] <- median(x[, j])
log_S_range <- c(5, 12)
grid_size <- 200L

log_S_grid <- seq(
  from = log_S_range[1], to = log_S_range[2], length.out = grid_size
)


pdf(
  file = "Figures/variances_S_N_simulation_Gompertz.pdf",
  width = 6.5,
  height = 9
)

par(mfrow = c(n_cr, 3))

for (rr in 1:n_cr) {
  
  log_S_dens <- rep(0, grid_size)
  max_N <- 30L
  N_pmf <- rep(0, max_N + 1L)
  result <- result_c[[rr]]
  
  for (iter in 1:n_recorded) {
    
    N_pmf <- N_pmf + dnbinom(
      x = 0:max_N, size = result$r[iter], mu = result$lambda[iter]
    )
    
    for (r in 1:n_rep_pred) {
    
      ind <- n_rep_pred * (iter - 1L) + r
      
      log_S_dens <- log_S_dens + dnorm(
        x = log_S_grid,
        mean = sum(x_mode * result$gamma[iter,]) + delta_new_c[[rr]][ind],
        sd = sqrt(result$eta2[iter])
      )
    
    }
  }
  
  plot(
    x = density(result$sigma2, from = 0.9, to = 1.4),
    main = "",
    xlab = expression(sigma^2),
    lwd = 2
  )
  
  plot(
    x = log_S_grid,
    y = log_S_dens / (n_rep_pred * n_recorded),
    type = "l",
    main = titles[rr],
    xlab = expression(log(S[i])),
    ylab = "Posterior predictive density",
    lwd = 2
  )
  
  barplot(
    height = N_pmf / n_recorded,
    names.arg = 0:max_N,
    main = "",
    xlab = expression(N[i]),
    ylab = "Posterior predictive probability"
  )
  
}

dev.off()
```


## Marginal posterior of the number of clusters

```{r}
pdf(file = "Figures/n_cluster_simulation_Gompertz.pdf", width = 6.5, height = 3)

par(mfrow = c(1, n_cr))

for (r in 1:n_cr) {
  
  tmp <- table(factor(result_c[[r]]$K, levels = 2:6))
  
  barplot(
    height = tmp / sum(tmp),
    xlab = "Number of clusters",
    ylab = "Posterior probability",
    ylim = c(0, 1),
    main = titles[r]
  )

}

dev.off()
```


## Credible intervals

Compute and plot 95% posterior credible intervals for the regression coefficients 
β (solid lines) and γ (dashed lines) of each covariate. 

```{r}
# Make the covariate names prettier for plotting.
colnames(x) <- paste("Covariate", 1:2)

r_width <- 0.9
x_offset <- r_width / n_cr / 6

dir.create("Figures", showWarnings = FALSE)
pdf(file = "Figures/plot_CI_simulation_Gompertz.pdf", width = 6.5, height = 4)


# Function that draws the credible interval
plot_CI <- function(x, CI, lty = 1, col = "black") {
  
  # Draw the credible interval
  lines(x = rep(x, 2), y = CI[-1], lty = lty, lwd = 2)
  
  # Add horizontal delimters to both end of the credible interval
  for (y in CI[-1]) lines(
    x = c(x - x_offset / 2, x + x_offset / 2),
    y = rep(y, 2),
    lwd = 2,
    col = col
  )
  
  # Add a dot at the posterior mean
  points(x = x, y = CI[1], pch = 19, col = col)
  
}

ylim = c(-2.5, 2.5)
xlim = c(1 - r_width / 2, q + r_width / 2)

# Set up empty plot
plot(
  x = 0,
  type = 'n',
  xlim = xlim,
  ylim = ylim,
  xlab = "",
  ylab = "Regression coefficient",
  xaxt = "n"
)

# Add x-axis tick mark text
text(
  x = 1:q,
  y = ylim[1] - 1,
  labels = colnames(x),
  xpd = TRUE
)

abline(v = 0.5 + 1L:(q - 1L))

# Add lines at the true values
segments(x0 = xlim[1], y0 = -1, x1 = sum(xlim) / 2, col = "red")
segments(x0 = sum(xlim) / 2, y0 = 1, x1 = xlim[2], col = "red")

for (r in 1:n_cr) {
  result <- result_c[[r]]
  
  beta_CI <- matrix(data = NA_real_, nrow = q, ncol = 3)
  gamma_CI <- matrix(data = NA_real_, nrow = q, ncol = 3)
  
  beta_CI[, 1] <- colMeans(result$beta)
  gamma_CI[, 1] <- colMeans(result$gamma)
  
  for (k in 1:q) {
    beta_CI[k, 2:3] <- quantile(result$beta[, k], prob = c(0.025, 0.975))
    gamma_CI[k, 2:3] <- quantile(result$gamma[, k], prob = c(0.025, 0.975))
  }
  
  r_offset <- (r - 0.5 * n_cr - 0.5) * r_width / n_cr
  
  # Plot the q credible intervals
  for (k in 1:q) {
    plot_CI(x = k - x_offset + r_offset, CI = beta_CI[k, ])
    plot_CI(x = k + x_offset + r_offset, CI = gamma_CI[k, ], lty = 2)
    
    text(
      x = k + r_offset,
      y = ylim[2] + 0.5,
      labels = c("0%", "50%", "80%", "90%")[r],
      xpd = TRUE
    )
  }
  
}

for (k in 1:q) text(
  x = k,
  y = ylim[2] + 1,
  labels = "Censoring rate",
  xpd = TRUE
)

dev.off()
```

