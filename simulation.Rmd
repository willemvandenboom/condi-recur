---
title: "Simulation"
author: "Willem van den Boom"
date: "February 21, 2021"
output: html_document
---


## Generate data according to the model

The following uses parallel computing which I have only tested on macOS and Linux and might therefore not work on Windows operating systems.

```{r eval=FALSE}
# For parallel computing
if(!'doParallel' %in% rownames(installed.packages())) {
  install.packages('doParallel', dependencies = T)
}

censoring_rate <- c(0, 0.5, 0.8, 0.9)
n_cr <- length(censoring_rate)


# Set seed for reproducibility.
set.seed(20210221)

L <- 150L # Number of individuals
s <- rep(1:3, 50) # Cluster allocation
K <- max(s) # Number of clusters

# Generate the covariate values and their effects.
q = 2
x = matrix(data = runif(L * q), nrow = L, ncol = q)
beta = c(-1, 1)
gamma = c(-1, 1)

# Specify the random effects.
m <- matrix(data = NA_real_, nrow = L, ncol = 2)
m[, 1] <- s
for (h in 1:K) m[s == h, 2] <- (h - 2) * 0.8
delta <- s + 4

sigma2 <- 1
eta2 <- 1
lambda <- 7

N <- as.integer(qpois(
  p = runif(n = L, min = ppois(q = 0, lambda = lambda)),
  lambda = lambda
))

N_max <- max(N)

# The exponentiation can lead to `Inf`.
# We therefore use `pmin`.
S <- pmin(exp(rnorm(
  n = L,
  mean = x %*% gamma + delta,
  sd = sqrt(eta2)
)), 1e100)


# Generate Y from its distribution conditional on S using rejection sampling.
Y <- matrix(data = NA_real_, nrow = L, ncol = N_max)
T_all <- Y
for (i in 1:L) T_all[i, N[i]] <- Inf

for (i in 1:L) while(T_all[i, N[i]] > S[i]) for (j in 1:N[i]) {
  
  Y[i, j] <- rnorm(
    n = 1,
    mean = x[i, ] %*% beta + m[i, 1] + if (j > 1) m[i, 2] * (Y[i, j - 1L] - x[i, ] %*% beta - m[i, 1]) else 0,
    sd = sqrt(sigma2)
  )
  
  T_all[i, j] <- exp(Y[i, j]) + if (j > 1) T_all[i, j - 1L] else 0
  
}

# Generate data and run the Gibbs sampler for the r-th censoring rate.
run_Gibbs <- function (r) {
  
  # Set seed for reproducibility.
  set.seed(1)
  
  T_obs <- T_all
  n <- N
  c_i <- S
  
  cens <- rep(FALSE, L)
  cens[sample(L, size = round(censoring_rate[r] * L))] <- TRUE
  
  for (i in which(cens)) {
    c_i[i] <- runif(n = 1, min = T_all[i, 1], max = S[i])
    tmp <- T_all[i, 1:N[i]] <= c_i[i]
    T_obs[i, !tmp] <- NA_real_
    n[i] <- sum(tmp)
  }
  
  T_obs <- T_obs[, 1:max(n)]
  
  source("Gibbs_sampler.R")
  
  result <- Gibbs_sampler(
    T_obs = T_obs,
    n = n,
    c_i = c_i,
    cens = cens,
    x = x,
    n_iter = 2e5L,
    burnin = 2e4L,
    thin = 1e1L
  )
  
  return(list(result = result, n = n, cens = cens))
  
}

cl <- parallel::makeCluster(n_cr)
doParallel::registerDoParallel(cl)

# Fit the Gibbs sampler for each of the simulated data sets.
fit_list <- foreach::`%dopar%`(foreach::foreach(r = 1:n_cr), run_Gibbs(r))
parallel::stopCluster(cl)

result_c <- list()
n_c <- list()
cens_c <- list()

for (r in 1:n_cr) {
  result_c[[r]] <- fit_list[[r]]$result
  n_c[[r]] <- fit_list[[r]]$n
  cens_c[[r]] <- fit_list[[r]]$cens
}

rm(fit_list)
```


```{r include=FALSE, eval=FALSE}
dir.create("Data", showWarnings = FALSE)
save.image(file = "Data/simulation.RData", compress = TRUE)
```

```{r include=FALSE, eval=TRUE}
load(file = "Data/simulation.RData")
```


## Number of events

Compute and plot the CIs.

```{r}
titles <- paste0(100 * censoring_rate, "% censored")

pdf(
  file = paste0("Figures/N_CI_simulation.pdf"),
  width = 10,
  height = 15
)

par(mfrow = c(1, n_cr - 1), mar = c(4, 0, 3, 0))

y <- rank(
  x = 10000L * N + 100L * n_c[[4]] + colMeans(result_c[[4]]$N),
  ties.method = "random"
)

for (r in 2:n_cr) {
  
  result <- result_c[[r]]
  n <- n_c[[r]]
  cens <- cens_c[[r]]

  N_CI <- matrix(data = NA_real_, nrow = L, ncol = 3)
  
  N_CI[, 1] <- colMeans(result$N)
  
  for (i in 1:L) N_CI[i, 2:3] <- quantile(result$N[, i], prob = c(0.025, 0.975))
  
  # Plot an 'o' at the actual number of events.
  plot(
    x = N,
    y = y,
    pch = 1,
    xlim = c(1, 17),
    xlab = expression(italic("N"["i"])),
    ylab = "",
    yaxt = "n",
    main = titles[r]
  )
   
  for (i in which(cens)) {
    
    lines(x = N_CI[i,-1], y = rep(y[i], 2), lwd = 2)
    
    # Add an 'x' at the number of observed recurrent events.
    points(x = n[i], y = y[i], pch = 4)
    
    # Add a solid dot at the posterior mean.
    points(x = N_CI[i, 1], y = y[i], pch = 19)
    
  }

}

dev.off()
```


## Posterior predictive distributions of δ, mi0 and mi1

```{r}
pdf(file = "Figures/m_delta_new_simulation.pdf", width = 6.5, height = 9)
par(mfrow = c(n_cr, 2))

for (rr in 1:n_cr) {
  
  result <- result_c[[rr]]
  
  n_rep <- 3L
  n_recorded <- length(result$M)
  
  m_new <- matrix(NA_real_, nrow = n_rep * n_recorded, ncol = 2)
  delta_new <- rep(NA_real_, n_rep * n_recorded)
  
  sigma2_m <- 100
  sigma2_delta <- 100
  
  set.seed(1)
  
  for (iter in 1:n_recorded) for (r in 1:n_rep) {
    
    ind <- n_rep * (iter - 1L) + r
    
    if (runif(1) < L / (result$M[iter] + L)) {
      i <- sample.int(L, size = 1)
      m_new[ind, ] <- result$m[iter, i, ]
      delta_new[ind] <- result$delta[iter, i]
    } else {
      m_new[ind, ] <- rnorm(2, sd = sqrt(sigma2_m))
      delta_new[ind] <- rnorm(1, sd = sqrt(sigma2_delta))
    }
    
  }
  
  
  delta_lim <- c(2.5, 14)
  
  plot_2D_density <- function(y, ylim, zlim, ylab) {
    
    tmp <- MASS::kde2d(
      x = delta_new,
      y = y,
      h = 2 * c(MASS::bandwidth.nrd(delta_new), MASS::bandwidth.nrd(y)),
      n = 200L,
      lims = c(
        delta_lim + c(-.05, .05) * diff(delta_lim),
        ylim + c(-.05, .05) * diff(ylim)
      )
    )
    
    contour(
      x = tmp$x,
      y = tmp$y,
      z = log(tmp$z),
      xlim = delta_lim,
      ylim = ylim,
      zlim = zlim,
      drawlabels = FALSE,
      xlab = expression(delta[i]),
      ylab = ylab,
      main = titles[rr]
    )
    
  }
  
  
  plot_2D_density(
    y = m_new[, 1],
    ylim = c(-1, 5),
    zlim = c(-6, -1),
    ylab = expression('m'[i1])
  )
  
  plot_2D_density(
    y = m_new[, 2],
    ylim = c(-2, 2.5),
    zlim = c(-6, -1),
    ylab = expression('m'[i2])
  )
  
}

dev.off()
```


## Marginal posterior densities for $\sigma^2$, $\eta^2$ and $\lambda$.

```{r}
pdf(file = "Figures/variances_lambda_simulation.pdf", width = 6.5, height = 9)

par(mfrow = c(n_cr, 3))

for (r in 1:n_cr) {
  
  plot(
    x = density(result_c[[r]]$sigma2, from = 0.8, to = 1.3),
    main = "",
    xlab = expression(sigma^2),
    lwd = 2
  )
  
  plot(
    x = density(result_c[[r]]$eta2, from = 0, to = 6),
    main = titles[r],
    xlab = expression(eta^2),
    lwd = 2
  )
  
  plot(
    x = density(result_c[[r]]$lambda, from = 5.5, to = 8),
    main = "",
    xlab = expression(lambda),
    lwd = 2
  )
  
}

dev.off()
```


## Marginal posterior of the number of clusters

```{r}
pdf(file = "Figures/n_cluster_simulation.pdf", width = 6.5, height = 3)

par(mfrow = c(1, n_cr))

for (r in 1:n_cr) {
  
  tmp <- table(factor(result_c[[r]]$K, levels = 3:7))
  
  barplot(
    height = tmp / sum(tmp),
    xlab = "Number of clusters",
    ylab = "Posterior probability",
    ylim = c(0, 1),
    main = titles[r]
  )

}

dev.off()
```


## Credible intervals

Compute and plot 95% posterior credible intervals for the regression coefficients 
β (solid lines) and γ (dashed lines) of each covariate. 

```{r}
# Make the covariate names prettier for plotting.
colnames(x) <- paste("Covariate", 1:2)

r_width <- 0.9
x_offset <- r_width / n_cr / 6

dir.create("Figures", showWarnings = FALSE)
pdf(file = "Figures/plot_CI_simulation.pdf", width = 6.5, height = 4)


# Function that draws the credible interval
plot_CI <- function(x, CI, lty = 1, col = "black") {
  
  # Draw the credible interval
  lines(x = rep(x, 2), y = CI[-1], lty = lty, lwd = 2)
  
  # Add horizontal delimters to both end of the credible interval
  for (y in CI[-1]) lines(
    x = c(x - x_offset / 2, x + x_offset / 2),
    y = rep(y, 2),
    lwd = 2,
    col = col
  )
  
  # Add a dot at the posterior mean
  points(x = x, y = CI[1], pch = 19, col = col)
  
}

ylim = c(-7, 4.5)

# Set margins to make room for x axis labels
par(mar = c(2, 4, 3, 0) + 0.1)
xlim = c(1 - r_width / 2, q + r_width / 2)

# Set up empty plot
plot(
  x = 0,
  type = 'n',
  xlim = xlim,
  ylim = ylim,
  xlab = "",
  ylab = "Regression coefficient",
  xaxt = "n"
)

# Add x-axis tick mark text
text(
  x = 1:q,
  y = ylim[1] - 1,
  labels = colnames(x),
  xpd = TRUE
)

abline(v = 0.5 + 1L:(q - 1L))

# Add lines at the true values
segments(x0 = xlim[1], y0 = -1, x1 = sum(xlim) / 2, col = "red")
segments(x0 = sum(xlim) / 2, y0 = 1, x1 = xlim[2], col = "red")

for (r in 1:n_cr) {
  result <- result_c[[r]]
  
  beta_CI <- matrix(data = NA_real_, nrow = q, ncol = 3)
  gamma_CI <- matrix(data = NA_real_, nrow = q, ncol = 3)
  
  beta_CI[, 1] <- colMeans(result$beta)
  gamma_CI[, 1] <- colMeans(result$gamma)
  
  for (k in 1:q) {
    beta_CI[k, 2:3] <- quantile(result$beta[, k], prob = c(0.025, 0.975))
    gamma_CI[k, 2:3] <- quantile(result$gamma[, k], prob = c(0.025, 0.975))
  }
  
  r_offset <- (r - 0.5 * n_cr - 0.5) * r_width / n_cr
  
  # Plot the q credible intervals
  for (k in 1:q) {
    plot_CI(x = k - x_offset + r_offset, CI = beta_CI[k, ])
    plot_CI(x = k + x_offset + r_offset, CI = gamma_CI[k, ], lty = 2)
    
    text(
      x = k + r_offset,
      y = ylim[2] + 1,
      labels = c("0%", "50%", "80%", "90%")[r],
      xpd = TRUE
    )
  }
  
}

for (k in 1:q) text(
  x = k,
  y = ylim[2] + 2,
  labels = "Censoring rate",
  xpd = TRUE
)

dev.off()
```